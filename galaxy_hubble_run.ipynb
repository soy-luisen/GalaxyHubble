{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d998e23-519b-428b-b826-c15f2827fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Masterâ€™s thesis - UNIR - Luis Enrique Ramirez Pelaez - 2023\n",
    "Deep Learning as an alternative to deconvolution of galaxy images captured with the space telescope Hubble\n",
    "Code developed\n",
    "------------------------------------------------------------------\n",
    "    https://www.linkedin.com/in/soy-luisen/ \n",
    "    https://github.com/soy-luisen/GalaxyHubble\n",
    "------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Main project.\n",
    "\n",
    "\"\"\"\n",
    "import cv2, os, glob, time, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import convolve2d as conv2\n",
    "\n",
    "from skimage import color, data, restoration, io, exposure\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "from astropy.visualization import astropy_mpl_style, ImageNormalize, SqrtStretch, MinMaxInterval,imshow_norm\n",
    "plt.style.use(astropy_mpl_style)\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from keras_unet.models import vanilla_unet, satellite_unet, custom_unet\n",
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, utils\n",
    "from tensorflow.keras.layers import Input , Conv2D , MaxPooling2D , Dropout , concatenate , UpSampling2D, Normalization, Rescaling\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ebcc34-47d1-459d-bebf-684f42d0bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python magic syntax to reload modules if they have changed. This avoids having to reset the kernel and lose everything.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import arquitecturas\n",
    "import ejecucion\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941b9fa-1457-4b9b-a37d-9026a8157303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability cuda\n",
    "ejecucion.is_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfdc3e2-d41e-470b-8b5a-6143f09d3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "## DATASET GENERAL PARAMS\n",
    "###########################################\n",
    "imtope=128 #The value chosen for the size of the images in the dataset.\n",
    "carpeta_dataset=\".\\\\dataset\\\\\"        #Folder with dataset files \n",
    "carpeta_resultados=\".\\\\results\\\\\"  #Folder to save results\n",
    "carpeta_pretrained_models=\".\\\\pretrained_models\\\\\"  #Folder to load pretrained models\n",
    "\n",
    "#List of .fits files with galaxy images of dataset.\n",
    "dataset_files=['dataset_galaxy128_1.fits','dataset_galaxy128_2.fits','dataset_galaxy128_3.fits',\n",
    "               'dataset_galaxy128_4.fits','dataset_galaxy128_5.fits','dataset_galaxy128_6.fits',\n",
    "               'dataset_galaxy128_7.fits','dataset_galaxy128_8.fits','dataset_galaxy128_9.fits',\n",
    "               'dataset_galaxy128_10.fits','dataset_galaxy128_11.fits',\n",
    "               'dataset_galaxy128_20.fits','dataset_galaxy128_21.fits']           \n",
    "\n",
    "#List of .fits files with deconvolutioned galaxy images of dataset (targets)\n",
    "dataset_deconv_files=[\"dataset_galaxy128_deconv_1.fits\",\"dataset_galaxy128_deconv_2.fits\",\"dataset_galaxy128_deconv_3.fits\",\n",
    "                      \"dataset_galaxy128_deconv_4.fits\",\"dataset_galaxy128_deconv_5.fits\",\"dataset_galaxy128_deconv_6.fits\",\n",
    "                      \"dataset_galaxy128_deconv_7.fits\",\"dataset_galaxy128_deconv_8.fits\",\"dataset_galaxy128_deconv_9.fits\",\n",
    "                      \"dataset_galaxy128_deconv_10.fits\",\"dataset_galaxy128_deconv_11.fits\",\n",
    "                      \"dataset_galaxy128_deconv_20.fits\",\"dataset_galaxy128_deconv_21.fits\"]  \n",
    "\n",
    "#List of test images to display.\n",
    "imagenes_a_mostrar=[0,1,3,7,8,9,16,22,28,41,48,63,65,557,578,588,633,674,706,810,872]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c853cde1-9412-454c-833c-469ccc3d1007",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Import dataset\n",
    "# X: read images from .fits files\n",
    "# Y: deconvolutioned images from .fits files\n",
    "# X_test: Test images\n",
    "# Y_test: Deconvolutioned test images (to predict)\n",
    "############################################\n",
    "\n",
    "# Dataset load\n",
    "X,Y = dataset.carga_dataset([0,1,2,3,4,5,6,7,8,9,11],carpeta_dataset,dataset_files,dataset_deconv_files)    #Training data,\n",
    "x_test,y_test = dataset.carga_dataset([10,12],carpeta_dataset,dataset_files,dataset_deconv_files)  #Test data.\n",
    "\n",
    "print(\"Loaded \"+str(len(X))+\" images for training.\")\n",
    "print(\"Loaded \"+str(len(x_test))+\" images for test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89b2b2-5edb-4b2e-9973-9e3a38241296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random division of the dataset into training and validation in 80-20 ratio.\n",
    "# If random_state=None each division is different.\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c53446-cc69-4fd9-953e-f809cc85f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecuta_prueba(nombre_modelo,input_shape,epochs,batch_size,optimizer,lr,loss,metrics,dub=0):\n",
    "    \"\"\"\n",
    "    Runs a complete test, displaying results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    nombre_modelo: Type of model to build\n",
    "    input_shape: Image input, rows x columns x depth\n",
    "    epochs: Number of epochs to training.\n",
    "    batch_size: Value of batch size to training.\n",
    "    optimizer: Type of optimizer.\n",
    "    lr: Value of learning rate.\n",
    "    loss: Value of loss rate.\n",
    "    metrics: Type of metric to training.\n",
    "    dub: Only for DIDN's architectures. Number of processing units. Default 0.\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    none   \n",
    "    \"\"\"   \n",
    "    \n",
    "    # It resets state and model to avoid problems in successive trainings.        \n",
    "    ejecucion.reset_keras()\n",
    "    time.sleep(10)    \n",
    "    \n",
    "    # Start run time. Only compilation and training time.\n",
    "    tiempo_inicio=time.time()\n",
    "    \n",
    "    # Test name to write in result filename.\n",
    "    print(\"********************************************************************\")    \n",
    "    if (dub>0):  #DIDN models has another param, dub, that is added to the name.\n",
    "        nombre_prueba=\"modelo_\"+nombre_modelo+\"DUB\"+str(dub)\n",
    "    else:\n",
    "        nombre_prueba=\"modelo_\"+nombre_modelo\n",
    "        \n",
    "    nombre_prueba = nombre_prueba+\"_\"+optimizer+str(format(lr,\".1E\"))+\"_\"+loss+\"_\"+metrics+\"_\"+str(batch_size)+\"_\"+str(epochs)  \n",
    "    print(\"PRUEBA: \"+nombre_prueba);    \n",
    "    \n",
    "    # The model indicated in the parameter is created\n",
    "    modelo=arquitecturas.crea_modelo(nombre_modelo,input_shape,dub=dub)  \n",
    "    \n",
    "    # Training of model\n",
    "    history=ejecucion.entrena_modelo(modelo, x_train, y_train, x_val, y_val, input_shape = input_shape,\n",
    "                                     epochs=epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, loss=loss, metrics=metrics)\n",
    "\n",
    "    # Training graphics are shown\n",
    "    resultados_prediccion_texto=ejecucion.muestra_estadisticas_entrenamiento(history,modelo,x_test,y_test,carpeta_resultados+nombre_prueba)\n",
    "    \n",
    "    tiempo_fin=round(time.time() - tiempo_inicio)\n",
    "    \n",
    "    # Predictions are made and results are shown\n",
    "    # 'num' predictions are displayed\n",
    "    # If az=True 'Num' random predictions are displayed\n",
    "    # If az=False y num>0 The first 'num' prediction images are displayed\n",
    "    # If az=False y num=0 The images of 'imagenes_a_mostrar' are displayed  (concrete images of the test data)\n",
    "    predictions=ejecucion.muestra_predicciones(modelo,x_test,y_test,carpeta_resultados+nombre_prueba,0,imagenes_a_mostrar,az=False)\n",
    "    \n",
    "    # Metrics (deconvolutioned images versus predicts images)\n",
    "    predictions_form=predictions[:,:,:,0]\n",
    "    MSE_pred = ejecucion.obtain_MSE(y_test,predictions_form)\n",
    "    metricas_texto=\"MSE: \"+str(MSE_pred)+\"\\n\"\n",
    "    RMSE = math.sqrt(MSE_pred)\n",
    "    metricas_texto += \"RMSE: \"+str(RMSE)+\"\\n\"\n",
    "    PSNR_pred = ejecucion.obtain_PSNR(MSE_pred, bits = 8)\n",
    "    metricas_texto += \"PSNR: \"+str(PSNR_pred)+\"\\n\"\n",
    "    SSIM_pred = ejecucion.obtain_SSIM(y_test, predictions_form)\n",
    "    metricas_texto += \"SSIM: \"+str(SSIM_pred)+\"\\n\"\n",
    "\n",
    "    resultados_totales=nombre_prueba+\"\\nPREDICTIONS RESULTS:\\n\"+resultados_prediccion_texto+\"\\nMETRICS:\\n\"+metricas_texto\n",
    "    resultados_totales=resultados_totales+\"\\nEXECUTION TIME: \"+str(tiempo_fin)+\" seconds\"\n",
    "    print(resultados_totales)\n",
    "    \n",
    "    # Results are saved in text mode\n",
    "    with open(carpeta_resultados+nombre_prueba+\".txt\", \"w\") as text_file:\n",
    "        text_file.write(\"%s\" % resultados_totales)\n",
    "    \n",
    "    # Model and predictions are saved\n",
    "    modelo.save(carpeta_resultados+nombre_prueba+\".h5\")\n",
    "    \n",
    "    # Uncoment next line to save predictions.\n",
    "    #ejecucion.guarda_predicciones(predictions,nombre_prueba+\".fits\",carpeta_dataset)\n",
    "\n",
    "    print(\"END TEST: \"+nombre_prueba);\n",
    "\n",
    "def ejecuta_prueba_preentrenada(modelo_pretraining):  \n",
    "    \"\"\"\n",
    "    A pretrained model is loaded from a .h5 file. The name of this file already carries the parameterization for the names of the images.\n",
    "    Predictions are made with the test data, and the results are displayed.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    modelo_pretraining: Pretrained model file name.   \n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    none   \n",
    "    \"\"\"   \n",
    "   \n",
    "    # Load model\n",
    "    modelo = ejecucion.carga_modelo(carpeta_pretrained_models,modelo_pretraining)\n",
    "    \n",
    "    nombre_prueba = modelo_pretraining[:-3]                       \n",
    "    # Test name\n",
    "    print(\"********************************************************************\") \n",
    "    print(\"TEST pretrained model: \"+nombre_prueba);    \n",
    "                               \n",
    "    # Predictions are made and results are shown\n",
    "    # 'num' predictions are displayed\n",
    "    # If az=True 'Num' random predictions are displayed\n",
    "    # If az=False y num>0 The first 'num' prediction images are displayed\n",
    "    # If az=False y num=0 The images of 'imagenes_a_mostrar' are displayed  (concrete images of the test data)\n",
    "    predictions=ejecucion.muestra_predicciones(modelo,x_test,y_test,carpeta_resultados+nombre_prueba,0,imagenes_a_mostrar,az=False)\n",
    "    \n",
    "    # Metrics (deconvolutioned images versus predicts images)\n",
    "    predictions_form=predictions[:,:,:,0]\n",
    "    MSE_pred = ejecucion.obtain_MSE(y_test,predictions_form)\n",
    "    metricas_texto=\"MSE: \"+str(MSE_pred)+\"\\n\"\n",
    "    RMSE = math.sqrt(MSE_pred)\n",
    "    metricas_texto += \"RMSE: \"+str(RMSE)+\"\\n\"\n",
    "    PSNR_pred = ejecucion.obtain_PSNR(MSE_pred, bits = 8)\n",
    "    metricas_texto += \"PSNR: \"+str(PSNR_pred)+\"\\n\"\n",
    "    SSIM_pred = ejecucion.obtain_SSIM(y_test, predictions_form)\n",
    "    metricas_texto += \"SSIM: \"+str(SSIM_pred)+\"\\n\"\n",
    "    \n",
    "    resultados_totales=nombre_prueba+\"\\nMETRICS:\\n\"+metricas_texto\n",
    "    print(resultados_totales)\n",
    "    \n",
    "    # Results are saved in text mode\n",
    "    with open(carpeta_resultados+nombre_prueba+\"_TEST.txt\", \"w\") as text_file:\n",
    "        text_file.write(\"%s\" % resultados_totales)\n",
    "        \n",
    "    print(\"END TEST: \"+nombre_prueba);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6a4a8-3644-4200-ad14-3465621eb303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RUN TEST. \n",
    "You can modify\n",
    "\n",
    "epoch: 100, 150, 200\n",
    "batch_size: 32, 64, 128, 256\n",
    "lr: 0.001, 0.0001, 0.00001. 0.000001\n",
    "\n",
    "EXAMPLES\n",
    "\n",
    "ejecuta_prueba(nombre_modelo=\"unetclassic4\",input_shape=(128,128,1),epochs=100,batch_size=32,optimizer=\"adam\",lr=0.001,loss=\"ssim\",metrics=\"mean_absolute_error\")\n",
    "ejecuta_prueba(nombre_modelo=\"unetclassic8\",input_shape=(128,128,1),epochs=100,batch_size=32,optimizer=\"adam\",lr=0.001,loss=\"ssim\",metrics=\"mean_absolute_error\")\n",
    "ejecuta_prueba(nombre_modelo=\"unetclassic16\",input_shape=(128,128,1),epochs=100,batch_size=32,optimizer=\"adam\",lr=0.001,loss=\"ssim\",metrics=\"mean_absolute_error\")\n",
    "ejecuta_prueba(nombre_modelo=\"unetclassic32\",input_shape=(128,128,1),epochs=100,batch_size=32,optimizer=\"adam\",lr=0.001,loss=\"ssim\",metrics=\"mean_absolute_error\")\n",
    "ejecuta_prueba(nombre_modelo=\"unetclassic64\",input_shape=(128,128,1),epochs=100,batch_size=32,optimizer=\"adam\",lr=0.001,loss=\"ssim\",metrics=\"mean_absolute_error\")\n",
    "ejecuta_prueba(nombre_modelo=\"unetclassic128\",input_shape=(128,128,1),epochs=100,batch_size=32,optimizer=\"adam\",lr=0.001,loss=\"ssim\",metrics=\"mean_absolute_error\")\n",
    "\n",
    "ejecuta_prueba(nombre_modelo=\"DIDN16\",input_shape=(128,128,1),epochs=150,batch_size=32,optimizer=\"adam\",lr=0.001,loss=\"ssim\",metrics=\"mean_absolute_error\",dub=1)\n",
    "ejecuta_prueba(nombre_modelo=\"DIDN16\",input_shape=(128,128,1),epochs=150,batch_size=32,optimizer=\"adam\",lr=0.001,loss=\"ssim\",metrics=\"mean_absolute_error\",dub=2)\n",
    "\n",
    "ejecuta_prueba(nombre_modelo=\"AEPP2\",input_shape=(128,128,1),epochs=100,batch_size=32,optimizer=\"adam\",lr=0.001,loss=\"ssim\",metrics=\"mean_absolute_error\")\n",
    "\n",
    "RUN PRETRAINING MODEL\n",
    "ejecuta_prueba_preentrenada(\"modelo_unetclassic16_adam_ssim_mean_absolute_error_64_100.h5\")\n",
    "ejecuta_prueba_preentrenada(\"modelo_DIDN16DUB2_adam1.0E-03_ssim_mean_absolute_error_64_150.h5\")\n",
    "ejecuta_prueba_preentrenada(\"modelo_AEPP2_adam1.0E-03_ssim_mean_absolute_error_64_200.h5\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2571f3-2d55-4266-9bfd-6a23c6b80ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejecuta_prueba(nombre_modelo=\"unetclassic16\",input_shape=(128,128,1),epochs=5,batch_size=64,optimizer=\"adam\",lr=0.001,loss=\"ssim\",metrics=\"mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8827c0-874e-4f7a-8143-8d0de7953977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejecuta_prueba_preentrenada(\"modelo_AEPP2_adam1.0E-03_ssim_mean_absolute_error_64_200.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
